{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhtrg/data_mining/blob/main/Result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsE034il0JmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c0edb1-8778-4e79-fe5a-e878f058ca9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.56.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (0.39.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (4.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->pyod) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->pyod) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.2)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->pyod) (2022.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyod\n",
        "from pyod.models.knn import KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXXZGNyU0jKU"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", lineno=0)\n",
        "# warnings.filterwarnings(\"ignore\", lineno=451) # IsolationForest warning\n",
        "# warnings.filterwarnings(\"ignore\", lineno=17)  # regex warning\n",
        "# warnings.filterwarnings(\"ignore\", lineno=16)  # regex warning\n",
        "# warnings.filterwarnings(\"ignore\", lineno=4913) # caveat warning for copy of slice\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76EZ3wiK0n7x"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, KFold,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler # may not need if used with vectorized data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.tree import _tree\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import adjusted_rand_score, completeness_score, v_measure_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO6KFG3Q0vX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429acdc9-a8a8-4813-9212-a02d3d96dcd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(['stopwords','punkt'])\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('opinion_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMTE1rzY04RZ"
      },
      "outputs": [],
      "source": [
        "# to optimize display of dataframe in run window\n",
        "desired_width = 500\n",
        "pd.set_option('display.width', desired_width)\n",
        "pd.set_option('display.max_columns', 30)\n",
        "pd.set_option('display.max_rows', 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8_iUUPW05gJ"
      },
      "outputs": [],
      "source": [
        "# produce csv output\n",
        "def saveOut(df, textIn):\n",
        "  ''' function creates a csv file for output\n",
        "  parameter: single dataframe, file name\n",
        "  return: notification of saved file + .csv file saved to directory  '''\n",
        "  fileName = textIn\n",
        "  df.to_csv(fileName, index=False)\n",
        "  print(f\"file {fileName} save complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr51PdTOmUZc"
      },
      "outputs": [],
      "source": [
        "# inspect and describe\n",
        "def inspect_data(data):\n",
        "  # summary of dataset inspection\n",
        "  stats = data.describe()\n",
        "  r, col = data.shape\n",
        "  check_error = data.isna().sum()\n",
        "  check_missing = data.isnull().sum()\n",
        "  checks = check_error.append(check_missing)\n",
        "  # print(checks)\n",
        "  problems = 0\n",
        "  for c in checks:\n",
        "    if c != 0:\n",
        "      problems += 1\n",
        "  all_feats = [x for x in data.columns]\n",
        "  use1_feats = all_feats[5:]\n",
        "  print(f\"Our Sentiment Analysis dataset from Yelp! consists of {r} instances with {col} features.\\n\")\n",
        "  print(f\"There are {problems} missing values\")\n",
        "  print(f\"In addition to {all_feats[4]}, we will keep the following features for our analysis:\\n{use1_feats}\\n{'*'*90}\")\n",
        "  return stats, use1_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_AbTRuUYSjn"
      },
      "outputs": [],
      "source": [
        "# create average columns\n",
        "def expand_dataset(data):\n",
        "  all_feats = [x for x in data.columns]\n",
        "  use2_feats = all_feats[4:]\n",
        "  snapshot_df = pd.DataFrame(data[use2_feats])\n",
        "  valenceAvg = [round((r1+r2)/2) for r1, r2 in zip(snapshot_df[\"Rater 1 - Valence\"], snapshot_df[\"Rater 2 - Valence\"])]\n",
        "  arousalAvg = [round((r1+r2)/2) for r1, r2 in zip(snapshot_df[\"Rater 1 - Arousal\"], snapshot_df[\"Rater 2 - Arousal\"])]\n",
        "  snapshot_df.insert(5,\"Average - Valence\", valenceAvg)\n",
        "  snapshot_df.insert(6,\"Average - Arousal\", arousalAvg)\n",
        "  reference_numbering = [f\"ref_{i:04}\" for i in data[\"No.\"]]\n",
        "  snapshot_df.insert(0,\"ReferenceOrder\",reference_numbering)\n",
        "  # print(f\"\\nrevised dataset:\\n{snapshot_df}\")\n",
        "  return snapshot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgKXbztPWQjp"
      },
      "outputs": [],
      "source": [
        "def report_means(data):\n",
        "  stats = data.describe()\n",
        "  all_feats = [x for x in data.columns]\n",
        "  use3_feats = all_feats[2:]\n",
        "  index = 0\n",
        "  category = []\n",
        "  meanScore = []\n",
        "  stdDev = []\n",
        "  modeScore = []\n",
        "  for i in use3_feats:\n",
        "    feat = use3_feats[index]\n",
        "    category.append(feat)\n",
        "    meanScore.append(stats[feat][1])\n",
        "    stdDev.append(stats[feat][2])\n",
        "    modeScore.append(data[feat].mode()[0])\n",
        "    index += 1\n",
        "  rater_stats = {\"Category\":category,\"ModeScore\":modeScore, \"MeanScore\":meanScore, \"StdDev\":stdDev}\n",
        "  raterStats_df = pd.DataFrame(rater_stats)\n",
        "  pd.options.display.float_format = '{:.3f}'.format\n",
        "  print(f\"\\n{raterStats_df}\\n{'*'*90}\")\n",
        "  return raterStats_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvybjG8IFS28"
      },
      "source": [
        "###### In consideration of reducing the number of class labels for all models, the following scale will be used:\n",
        "\n",
        "\n",
        "*   negative [1-2]\n",
        "*   somewhat negative [3-4]\n",
        "*   neutral [5]\n",
        "*   somewhat positive [6-7]\n",
        "*   positive [8-9]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWGF6D_zKLXm"
      },
      "outputs": [],
      "source": [
        "# to reduce class to categorical bins\n",
        "def relabel(df):\n",
        "  newClass_df = pd.DataFrame(df)\n",
        "  all_feats = [x for x in df.columns]\n",
        "  use4_feats = all_feats[2:]\n",
        "\n",
        "  def inner_build(feature):\n",
        "    convertedScore = []\n",
        "    for rank in df[feature]:\n",
        "      if rank < 3:\n",
        "        convertedScore.append(\"negative\")\n",
        "      elif rank < 5:\n",
        "        convertedScore.append(\"somewhat negative\")\n",
        "      elif rank == 5:\n",
        "        convertedScore.append(\"neutral\")\n",
        "      elif rank < 8:\n",
        "        convertedScore.append(\"somewhat positive\")\n",
        "      else:\n",
        "        convertedScore.append(\"positive\")\n",
        "    return convertedScore\n",
        "\n",
        "  for feat in use4_feats:\n",
        "    cs = inner_build(feat)\n",
        "    feat_labeled = f\"X_{feat}\"\n",
        "    newClass_df[feat_labeled] = cs\n",
        "\n",
        "  temp1 = df.iloc[:,:2]\n",
        "  temp2 = newClass_df.iloc[:,8:]\n",
        "  newRatings_df = pd.concat([temp1,temp2], axis=1, join='inner')\n",
        "\n",
        "  # print(newRatings_df)\n",
        "  return newRatings_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-Rjht-ZBZiH"
      },
      "outputs": [],
      "source": [
        "def clean_all_text(df):\n",
        "  ''' preprocessing function uses regex to clean text for vectorizing\n",
        "  parameter: original dataframe\n",
        "  return: dataframe with stripped down text in \"Review text\" column '''\n",
        "  df_new = df.copy(deep=True)\n",
        "  def reduce_lengthening(x_text):\n",
        "    # to reduce extra letters that are deliberate mispellings for emphasis\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    return pattern.sub(r\"\\1\\1\", x_text)\n",
        "  def clean_URLs(x_text):\n",
        "    return re.sub('((www.[^s]+)|(https?://[^s]+)|([^s]+\\.com[^s]+)|([A-Za-z0-9_]+\\.[A-Za-z0-9_]))','',x_text)\n",
        "  def clean_hyphen(x_text):\n",
        "    pattern = re.compile(r\"-\")\n",
        "    return pattern.sub(r\"\", x_text)\n",
        "\n",
        "  df_new['Review text'] = df_new['Review text'].apply(lambda x: reduce_lengthening(x))\n",
        "  df_new['Review text'] = df_new['Review text'].apply(lambda x: clean_URLs(x))\n",
        "  df_new['Review text'] = df_new['Review text'].apply(lambda x: clean_hyphen(x))\n",
        "  df_new['Review text'] = df_new['Review text'].astype(str).str.replace(r'([\\'|\\*|+])','')\n",
        "  df_new['Review text'] = df_new['Review text'].astype(str).str.replace(r'([\\.\\.|\\.])',' ')\n",
        "  df_new['Review text'] = df_new['Review text'].astype(str).str.replace(r'/',' ')\n",
        "\n",
        "  return df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XDUu6MjHrBi"
      },
      "outputs": [],
      "source": [
        "def word_exclusion(df):\n",
        "  ''' preprocessing function uses nltk to tokenize text for vectorizing\n",
        "  parameter: cleaned dataframe\n",
        "  return: dataframe with essential text in \"Review text\" column '''\n",
        "  # filter stop words and punctuation\n",
        "  def extract_words(x_text):\n",
        "    stop_words = set(stopwords.words('english')) - {'not'}\n",
        "    word_tokens = word_tokenize(x_text)\n",
        "    filtered_text = [w.lower().strip() for w in word_tokens if not (w.strip() == '' or w in stop_words or w  in [',','.','|','~']) and not (len(w) == 1 and isinstance(w,str))]\n",
        "    return filtered_text\n",
        "  def lemmatizer_on_text(x_text):\n",
        "    # replaces misspelled word with closest approximation from the WordNet corpus\n",
        "    lm = WordNetLemmatizer()\n",
        "    lemmed_text = \"\".join(lm.lemmatize(w)+\" \" for w in x_text)\n",
        "    return lemmed_text\n",
        "\n",
        "  df['Tokenized Review text']= df['Review text'].apply(lambda x: extract_words(x))\n",
        "  df['Review text'] = df['Tokenized Review text'].apply(lambda x: lemmatizer_on_text(x))\n",
        "  temp = df.pop('Tokenized Review text')\n",
        "  df.insert(2, 'Tokenized Review text', temp)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQKkBr1kQHs2"
      },
      "outputs": [],
      "source": [
        "# to create a bag of words that results in vector values\n",
        "def bag_of_vectors(df):\n",
        "  '''preprocessing function uses sklearn to normalize tokenized text based on frequencies in the document\n",
        "  parameter: tokenized dataframe\n",
        "  return: df_bow -- features are individual words found in text, values are vectors\n",
        "        : vectorBow_df -- df_bow with reference features and original text blob appended (not currently used) '''\n",
        "  bagStart_time = time.time()\n",
        "  print(f\"{'@@@'} Start bagging process...\")\n",
        "  this_df = pd.DataFrame(df)\n",
        "  vectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode')\n",
        "  X = vectorizer.fit_transform([review for review in this_df['Review text']])\n",
        "  df_bow = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())\n",
        "  #drop columns that contain numeric values\n",
        "  for col in df_bow.columns:\n",
        "    if re.search(r'\\d', col):\n",
        "      df_bow.drop(columns = col, inplace=True)\n",
        "  vectorBow_df = pd.concat([this_df,df_bow], axis=1, join='inner')\n",
        "  bagEnd_time = time.time()\n",
        "  delta_time = bagEnd_time - bagStart_time\n",
        "  print(f\"... Bagging completed in {delta_time:.4f} seconds {'@@@'}\")\n",
        "  return vectorBow_df, df_bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txyA8RcFFrb1"
      },
      "outputs": [],
      "source": [
        "# recode dataset for boolean options if a word is present in the document / instance value = 1, else = 0\n",
        "def transaction_set(df_all, df_matrix):\n",
        "  encodeStart_time = time.time()\n",
        "  print(f\"{'@@@'} Start encoding process...\")\n",
        "  df_transaction = df_all.copy(deep=True)\n",
        "  allFeats = [x for x in df_transaction.columns]\n",
        "  useFeats = allFeats[3:9]\n",
        "  # print(useFeats)\n",
        "\n",
        "  df_bools = df_matrix.copy(deep=True)\n",
        "  df_bools[df_bools > 0] = 1\n",
        "\n",
        "  for name in useFeats:\n",
        "    df_bools[name] = df_transaction[name]\n",
        "\n",
        "  encodeEnd_time = time.time()\n",
        "  delta_time = encodeEnd_time - encodeStart_time\n",
        "  print(f\"... Encoding completed in {delta_time:.4f} seconds {'@@@'}\")\n",
        "  # print(df_bools)\n",
        "\n",
        "  return df_bools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp-tVM0jgmDZ"
      },
      "outputs": [],
      "source": [
        "def validate_model(clf_name,classifier,df,target_df,k_fold):\n",
        "  \"\"\"this function implement k-fold cross-validation for classifier\n",
        "  params: clf_name: name of the classifier\n",
        "          classifier: classifier of interest\n",
        "          df: dataframe of independent attributes\n",
        "          target_df: a dataframe containing all targets of interest\n",
        "          k_fold: number of folds for cross-validation\n",
        "  return: a dataframe with 'precision_macro','recall_macro', 'f1_macro','accuracy' for the target columns\n",
        "  \"\"\"\n",
        "  report_dict = {}\n",
        "  metrics = ['precision_macro','recall_macro', 'f1_macro','accuracy']\n",
        "  print(f'{clf_name} classifier {k_fold}-fold cross-validation for all targets')\n",
        "  for target in target_df.columns:\n",
        "    scores = []\n",
        "\n",
        "    target_col = target_df[target]\n",
        "    for metric in metrics:\n",
        "      scores.append(np.mean(cross_val_score(classifier, df ,target_col, cv=k_fold,scoring = metric)))\n",
        "    report_dict[target]= scores\n",
        "  report_metric = pd.DataFrame(report_dict,index=metrics)\n",
        "  print(report_metric)\n",
        "  return report_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qfp9TicCB2A"
      },
      "outputs": [],
      "source": [
        "# Decision Tree classifier\n",
        "def decision_tree(df_textMatrix, target_df):\n",
        "  beginDT = time.time()\n",
        "  print(f\"\\n{'*'*90}\\nModeling Decision Tree ...\\n\")\n",
        "  dcs_tree = DecisionTreeClassifier(max_depth=10, random_state=1234)\n",
        "  P1_DT_report_metric = validate_model('Decision Tree',dcs_tree,df_textMatrix,target_df,10)\n",
        "  endDT = time.time()\n",
        "  delta_time = endDT-beginDT\n",
        "  print(f\"... Decision Tree took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "  return P1_DT_report_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WanQme_IUVz"
      },
      "outputs": [],
      "source": [
        "# Multinominal Naive Bayes Classifier\n",
        "def bayesMN(df_textMatrix, target_df):\n",
        "  beginMNB = time.time()\n",
        "  print(f\"\\n{'*'*90}\\nMulinominal Naive Bayes ...\\n\")\n",
        "  multi_naive_clf = MultinomialNB()\n",
        "  P1_MNB_report_metric = validate_model('Mulinominal Naive Bayes',multi_naive_clf,df_textMatrix,target_df,10)\n",
        "  endMNB = time.time()\n",
        "  delta_time = endMNB-beginMNB\n",
        "  print(f\"... Mulinominal Naive Bayes took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "  return P1_MNB_report_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrMK87uS5aPf"
      },
      "outputs": [],
      "source": [
        "def cluster_kmeans(matrix,target):\n",
        "  # requires normalized data -- using vectorized data\n",
        "  # requires target label values to be converted from nominal to values 0-4\n",
        "  target_lbl = target\n",
        "  target_lbl[target_lbl == \"negative\"] = 4\n",
        "  target_lbl[target_lbl == \"somewhat negative\"] = 3\n",
        "  target_lbl[target_lbl == \"neutral\"] = 2\n",
        "  target_lbl[target_lbl == \"positive\"] = 0\n",
        "  target_lbl[target_lbl == \"somewhat positive\"] = 1\n",
        "  def validate_cluster(clf_name,classifier,df,target_df,k_fold):\n",
        "    '''This function passes the k-means model to k-fold cross-validation with scoring unique to a cluster model\n",
        "    param:  clf_name - descriptive text\n",
        "            classifier - the model object\n",
        "            df - vectorized text matrix dataframe\n",
        "            target_df - class labels of 6 ratings related to the dataset\n",
        "            k-fold - integer, number of folds\n",
        "    return: report_metric -- a dataframe of the scores of each validated model '''\n",
        "    report_dict = {}\n",
        "    metrics = ['completeness_score','adjusted_rand_score', 'v_measure_score']\n",
        "    print(f'{clf_name} classifier {k_fold}-fold cross-validation for all targets')\n",
        "    for target in target_df.columns:\n",
        "      scores = []\n",
        "\n",
        "      target_col = target_df[target]\n",
        "      for metric in metrics:\n",
        "        scores.append(np.mean(cross_val_score(classifier, df ,target_col, cv=k_fold,scoring = metric)))\n",
        "      report_dict[target]= scores\n",
        "    report_metric = pd.DataFrame(report_dict,index=metrics)\n",
        "    print(report_metric)\n",
        "    return report_metric\n",
        "\n",
        "  beginKM = time.time()\n",
        "  print(f\"\\n{'*'*90}\\nModeling K-means cluster ...\\nthis process may take ~50 minutes to complete\")\n",
        "  km_model = KMeans(n_clusters=5, init=\"k-means++\", n_init=10, max_iter=300, random_state=51)\n",
        "  P1_KM_report_metric = validate_cluster(\"K-means Clustering\", km_model, matrix, target_lbl, 10)\n",
        "\n",
        "  endKM = time.time()\n",
        "  delta_time = endKM-beginKM\n",
        "  print(f\"... K-means cluster took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "  return P1_KM_report_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KuvQSSUJreS"
      },
      "outputs": [],
      "source": [
        "# Bernoulli Naive Bayes classifier\n",
        "def bayesBernoulli(df_textMatrix, target_df):\n",
        "  beginBNB = time.time()\n",
        "  bernoulli_naive_clf = BernoulliNB()\n",
        "  P3_CB_report_metric = validate_model('Bernoulli Naive Bayes',bernoulli_naive_clf,df_textMatrix,target_df,10)\n",
        "  endBNB = time.time()\n",
        "  delta_time = endBNB-beginBNB\n",
        "  print(f\"... BernoulliNaive Bayes took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "\n",
        "  return P3_CB_report_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_1ci6NpNUq6"
      },
      "outputs": [],
      "source": [
        "def ann_classifier(matrix,target):\n",
        "  # requires normalized data -- using vectorized data\n",
        "  def validate_ann(clf_name,classifier,df,target_df,k_fold):\n",
        "    '''This function passes the k-means model to k-fold cross-validation with scoring unique to a cluster model\n",
        "    param:  clf_name - descriptive text\n",
        "            classifier - the model object\n",
        "            df - vectorized text matrix dataframe\n",
        "            target_df - class labels of 6 ratings related to the dataset\n",
        "            k-fold - integer, number of folds\n",
        "    return: report_metric -- a dataframe of the scores of each validated model '''\n",
        "    report_dict = {}\n",
        "    metrics = ['precision_macro','recall_macro', 'f1_macro','accuracy']\n",
        "    print(f'{clf_name} classifier {k_fold}-fold cross-validation for all targets')\n",
        "    for target in target_df.columns:\n",
        "      scores = []\n",
        "\n",
        "      target_col = target_df[target]\n",
        "      le = LabelEncoder()\n",
        "      target_col = le.fit_transform(target_col)\n",
        "      for metric in metrics:\n",
        "        scores.append(np.mean(cross_val_score(classifier, df ,target_col, cv=k_fold,scoring = metric)))\n",
        "      report_dict[target]= scores\n",
        "    report_metric = pd.DataFrame(report_dict,index=metrics)\n",
        "    print(report_metric)\n",
        "    return report_metric\n",
        "  beginANN = time.time()\n",
        "  print(f\"\\n{'*'*90}\\nArtificial Neural Network ...\\nthis process may take ~1 hour to complete\")\n",
        "  target_lbl = target\n",
        "  ANN_model = MLPClassifier(hidden_layer_sizes=(50,50), learning_rate='adaptive', random_state=51)\n",
        "  P3_ANN_report_metric = validate_ann(\"Artificial Neural Network\", ANN_model, matrix, target_lbl, 5)\n",
        "  endANN = time.time()\n",
        "  delta_time = endANN-beginANN\n",
        "  print(f\"... Artificial Neural Network took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "  return P3_ANN_report_metric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHbO7l5-35-z"
      },
      "outputs": [],
      "source": [
        "def rules_based(df,target):\n",
        "  \"\"\" This function extracts and print out rules from a decision tree\n",
        "  param: df: a dataframe of independent features\n",
        "         target: name of the target column\n",
        "  return: display a dataframe of rules including antecedent, consequent, accuracy and coverage of each rule\n",
        "  \"\"\"\n",
        "  rules_filename = f\"{target}.csv\"\n",
        "  beginRules = time.time()\n",
        "  print(f\"\\n{'*'*90}\\nModeling with Rule-based ...\")\n",
        "\n",
        "\n",
        "  def get_rules(tree, feature_names, class_col):\n",
        "    \"\"\" This function extracts rules from a decision tree\n",
        "    param: tree: a tree object\n",
        "          feature_names: names of the independent attributes\n",
        "          class_col: the target column\n",
        "    return: a dataframe of rules including antecedent, consequent, accuracy and coverage of each rule\n",
        "    \"\"\"\n",
        "    tree_ = tree.tree_\n",
        "    feature_name = [\n",
        "          feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
        "          for i in tree_.feature\n",
        "      ]\n",
        "\n",
        "    paths = []\n",
        "    path = []\n",
        "    ante = []\n",
        "    conse = []\n",
        "    accuracy = []\n",
        "    cover = []\n",
        "    def recurse(node, path, paths):\n",
        "      \"\"\" This function recusively traverse the decision tree, store data of each node and decision path\n",
        "      param: node: node in the tree object\n",
        "            path: path to the target\n",
        "            paths: a list that stores all paths\n",
        "      \"\"\"\n",
        "\n",
        "      if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
        "          name = feature_name[node]\n",
        "          threshold = tree_.threshold[node]\n",
        "          p1, p2 = list(path), list(path)\n",
        "          p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
        "          recurse(tree_.children_left[node], p1, paths)\n",
        "          p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
        "          recurse(tree_.children_right[node], p2, paths)\n",
        "      else:\n",
        "          path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
        "          paths += [path]\n",
        "\n",
        "    recurse(0, path, paths)\n",
        "\n",
        "    # sort paths by samples count of each class label in each path\n",
        "    samples_count = [p[-1][1] for p in paths]\n",
        "    ii = list(np.argsort(samples_count))\n",
        "    paths = [paths[i] for i in reversed(ii)]\n",
        "\n",
        "    #store antecedent, consequent, accuracy and coverage of each rule in seperate lists\n",
        "    for path in paths:\n",
        "      rule = []\n",
        "      for p in path[:-1]:\n",
        "        if \"<=\" not in p:\n",
        "          rule.append(str(p))\n",
        "      ante.append(rule)\n",
        "      classes = path[-1][0][0]\n",
        "\n",
        "      l = np.argmax(classes)\n",
        "      conse.append(class_col[l])\n",
        "      accuracy.append(np.round(classes[l]/np.sum(classes),2))\n",
        "      cover.append(np.round(path[-1][1]/2000,2))\n",
        "\n",
        "    #create a dataframe of rules including antecedent, consequent, accuracy and coverage of each rule\n",
        "    rules = pd.DataFrame({'Antecedent':ante,'Consequent':conse,'Accuracy':accuracy,'Coverage':cover})\n",
        "\n",
        "    return rules\n",
        "\n",
        "\n",
        "  # Prepare the data data\n",
        "\n",
        "  X = df.iloc[:,:-6]\n",
        "  y = df[target]\n",
        "\n",
        "  # Fit the regressor, set max_depth = 3\n",
        "  dcs_tree = DecisionTreeClassifier(max_depth=10, random_state=1234)\n",
        "  model = dcs_tree.fit(X, y)\n",
        "  # Print rules\n",
        "  rules = get_rules(dcs_tree, X.columns, y)\n",
        "  DF_rules = pd.DataFrame(rules)\n",
        "  print(rules)\n",
        "  saveOut(DF_rules, rules_filename)\n",
        "  endRules = time.time()\n",
        "  delta_time = endRules-beginRules\n",
        "  print(f\"... Rule-based took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vaMWVvhaWqV"
      },
      "outputs": [],
      "source": [
        "def isolation_forest(df_o, df_matrix):\n",
        "  ''' This function detects whether an instance is an outlier and creates a csv file containing anomoulous instances\n",
        "  param: df -- a dataframe of only the vectorized values related to the \"Review text\"\n",
        "  return: if_outliers -- a dataframe containing instances of outliers/anomalies with their scores, a csv file of those instances, and a graph\n",
        "  '''\n",
        "  beginIF = time.time()\n",
        "  print(f\"\\n{'*'*90}\\nModeling Isolation Forest ...\")\n",
        "  df_transaction = df_matrix.copy(deep=True)\n",
        "  df_o = pd.DataFrame(df_o)\n",
        "  X_train, X_test = train_test_split(df_transaction, test_size=0.4,random_state=51)\n",
        "  # create isolation forest model and fit training data\n",
        "  iForest = IsolationForest(n_estimators=500,\n",
        "                            contamination=0.02,\n",
        "                            max_features=1000,\n",
        "                            random_state=51)\n",
        "  iForest.fit(X_train)\n",
        "\n",
        "  # store labels of predicted anomalies (1= inlier, -1= oulier)\n",
        "  if_labels_train = iForest.predict(X_train)\n",
        "  if_labels_test = iForest.predict(X_test)\n",
        "\n",
        "  # store anomaly scores\n",
        "  if_score_train = iForest.decision_function(X_train)\n",
        "  if_score_test = iForest.decision_function(X_test)\n",
        "\n",
        "  # stitch the labels and scores back together\n",
        "  X_train['outlierLabel'] = if_labels_train\n",
        "  X_test['outlierLabel'] = if_labels_test\n",
        "  X_train['outlierScore'] = if_score_train\n",
        "  X_test['outlierScore'] = if_score_test\n",
        "  rezipXframes = pd.concat([X_train, X_test])\n",
        "\n",
        "  # apply anomaly classification to the original dataset\n",
        "  df_o['outlierScore'] = rezipXframes['outlierScore']\n",
        "  df_o['outlierLabel'] = rezipXframes['outlierLabel']\n",
        "  labelTemp = df_o['outlierLabel']\n",
        "  df_o['is_outlier'] = [\"yes\" if x==-1 else \"no\" for x in labelTemp]\n",
        "\n",
        "  plt.scatter(df_o['outlierScore'],df_o['No.'], c=df_o['outlierLabel'], cmap='winter')\n",
        "  plt.title(\"Scatter Plot of Datapoints by IF Outlier Score\")\n",
        "  plt.xlabel(\"IF Outlier Score (outlier << 0)\")\n",
        "  plt.ylabel(\"Reference No.\")\n",
        "  plt.show()\n",
        "\n",
        "  # create dataframe of anomalies only\n",
        "  if_outliers = df_o.loc[df_o['is_outlier'] == \"yes\"]\n",
        "  if_outliers.drop(axis=1, columns=\"outlierLabel\", inplace=True)\n",
        "\n",
        "  print(f\"Created a dataframe containing the {if_outliers.shape[0]} items that were identified as outliers/anomalies from the dataset via Isolation Forest Model\")\n",
        "  # create csv of anomalies only\n",
        "  # saveOut(if_outliers, \"Isolation_Forest_outliers.csv\")\n",
        "\n",
        "  endIF = time.time()\n",
        "  delta_time = endIF-beginIF\n",
        "  print(f\"... Isolation Forsest took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "\n",
        "  return if_outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXqs4-B08zq8"
      },
      "outputs": [],
      "source": [
        "def knn_anomaly_detection(df_o, df_matrix):\n",
        "  ''' This function detects whether an instance is outlier and create a csv file containing anomoulous instances\n",
        "  param: vectorized_df: a dataframe of vectorized text\n",
        "  return: knn_outliers -- a dataframe containing outliers and create a csv file containing anomoulous instances\n",
        "  '''\n",
        "  beginKNN = time.time()\n",
        "  print(f\"\\n{'*'*90}\\nModeling K-nearest Neighbor ...\")\n",
        "  vectorized_df = df_matrix.copy(deep=True)\n",
        "  df_o = pd.DataFrame(df_o)\n",
        "  #create the knn models\n",
        "  mdl = KNN(n_neighbors=50, contamination=0.02)\n",
        "  mdl.fit(vectorized_df)\n",
        "\n",
        "  # Outlier scores\n",
        "  scores = mdl.decision_scores_\n",
        "  df_o['Outlier score'] = scores\n",
        "\n",
        "  #label of the records: 1 means outliers, 0 means not outliers\n",
        "  labels = mdl.labels_\n",
        "  df_o['is_outlier'] = labels\n",
        "\n",
        "  plt.scatter(df_o['Outlier score'],df_o['No.'],c= df_o['is_outlier'])\n",
        "  plt.title(\"Scatter Plot of Datapoints by KNN Outlier Score\")\n",
        "  plt.xlabel(\"KNN Outlier Score (outlier >> 1)\")\n",
        "  plt.ylabel(\"Reference No.\")\n",
        "  plt.show()\n",
        "\n",
        "  #change the 'is_outlier' value from 1 to 'yes' and 0 to 'no'\n",
        "  df_o['is_outlier'].replace(1,'yes',inplace = True)\n",
        "  df_o['is_outlier'].replace(0,'no',inplace = True)\n",
        "  knn_outliers=df_o.loc[df_o[\"is_outlier\"]=='yes']\n",
        "  print(f\"Created a dataframe containing the {knn_outliers.shape[0]} objects that were identified as outliers/anomalies from the dataset via KNN Model\")\n",
        "  # saveOut(knn_outliers, \"KNN_outliers.csv\")\n",
        "\n",
        "  endKNN = time.time()\n",
        "  delta_time = endKNN-beginKNN\n",
        "  print(f\"... K-nearest Neighbor took {delta_time:.4f} seconds to complete\\n{'*'*90}\\n\")\n",
        "\n",
        "\n",
        "  return knn_outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHXi7zbk2WM6"
      },
      "outputs": [],
      "source": [
        "# execute file\n",
        "def main():\n",
        "  original_data = pd.read_csv(r'https://raw.githubusercontent.com/farberta2022/DSC411_SP22_final/main/sampleReviewData_030822.csv')\n",
        "  # *** preprocessing standard***\n",
        "  inspect_data(original_data)\n",
        "  # returns revised dataset with reference to original, columns 4-8, and the two new average columns (all instances present)\n",
        "  revisedMain_df = expand_dataset(original_data)\n",
        "  # *** preprocessing special analysis***\n",
        "  print(f\"Statistical description of original dataset\")\n",
        "  raterStats_df = report_means(revisedMain_df)\n",
        "  # # returns revised dataset of reduced class labels targets\n",
        "  # df_w5rank has 8 columns - ref#, Review text, and six 5-rank columns\n",
        "  df_w5rank = relabel(revisedMain_df)\n",
        "  # # passes \"review text\" through text mining preprocessing steps\n",
        "  df_newText = clean_all_text(df_w5rank)\n",
        "  # df_newText2 has 9 columns - ref#, Review text, Tokenized Text, and six 5-rank columns\n",
        "  df_newText2 = word_exclusion(df_newText)\n",
        "  # df_baggedText includes 9 columns from above plus df_textMatrix of 10k+ columns of vectorized values\n",
        "  df_baggedText, df_textMatrix = bag_of_vectors(df_newText2)\n",
        "  # df_textEncoded includes df_textMatrix of 10k+ columns of boolean values + six  5-rank columns\n",
        "  df_textEncoded = transaction_set(df_baggedText, df_textMatrix)\n",
        "  #this datafrane store the target columns\n",
        "  target_df = df_textEncoded.iloc[:,-6:]\n",
        "\n",
        "  # # # Project 1: Classification Basics\n",
        "  # print(f\"\\n{'*'*90}\\n{'*'*40}Project  1{'*'*40}\")\n",
        "  # # Decision Tree classifier                                          **** tested, works\n",
        "  # P1_report1 = decision_tree(df_textMatrix, target_df)\n",
        "\n",
        "  # # Multinominal Naive Bayes Classifier since this would be a better choice than Decesion tree\n",
        "  # #                                                                  **** tested, works\n",
        "  # P1_report2 = bayesMN(df_textMatrix, target_df)\n",
        "\n",
        "  # # K-means cluster\n",
        "  # # TODO: need to test in this program, tests in dedicated program worked fine\n",
        "  # P1_report3 = cluster_kmeans(df_textMatrix,target_df)\n",
        "\n",
        "\n",
        "  # # # # # Project 2: detect outliers with ioslation forest algorithm\n",
        "  # # #TODO: check output for uniformity\n",
        "  # print(f\"\\n{'*'*90}\\n{'*'*40}Project  2{'*'*40}\")\n",
        "  # # # # Project 2: detect outliers with ioslation forest algorithm\n",
        "  # #                                                                  **** tested, works\n",
        "  # outlier_iForest = isolation_forest(original_data, df_textMatrix)\n",
        "  # # # # Project 2: detect outliers with knn-algorithm\n",
        "  # #                                                                  **** tested, works\n",
        "  # knn_anomaly_detection(original_data, df_textMatrix)\n",
        "  ##****** currently have saveOutput commented out in the anomaly detection functions*****\n",
        "\n",
        "  # # # # Project 3: Classification Advanced\n",
        "  # print(f\"\\n{'*'*90}\\n{'*'*40}Project  3{'*'*40}\")\n",
        "  # #Bernoulli Naive Bayes classifier, which only takes into consideration the presence of a word\n",
        "  # #                                                                  **** tested, works\n",
        "  # P3_report1 = bayesBernoulli(df_textMatrix, target_df)\n",
        "\n",
        "  #rules-based classifier                                          **** tested, works\n",
        "  for target in target_df.columns:\n",
        "    print(f'Rules-based mining for {target}')\n",
        "    rules_based(df_textEncoded,target)\n",
        "\n",
        "  ## Artificial Neural Network\n",
        "  # P3_report3 = ann_classifier(df_textMatrix,target_df)\n",
        "\n",
        "  # saveOut(df_baggedText, \"df_withBaggedText.csv\")\n",
        "  # saveOut(df_textMatrix, \"vect_textMatrix.csv\")\n",
        "  # saveOut(df_textEncoded, \"bool_textMatrix.csv\")\n",
        "  # print(f\"test code:\\t{type(feats_subset1)}\\n{feats_subset1}\")\n",
        "  # print(f\"\\ntest\\n{df_textEncoded}\")\n",
        "\n",
        "\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjNYas1f0qLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008f8e14-b1b4-44cd-939d-41596a72c9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Sentiment Analysis dataset from Yelp! consists of 2000 instances with 9 features.\n",
            "\n",
            "There are 0 missing values\n",
            "In addition to Review text, we will keep the following features for our analysis:\n",
            "['Rater 1 - Valence', 'Rater 1 - Arousal', 'Rater 2 - Valence', 'Rater 2 - Arousal']\n",
            "******************************************************************************************\n",
            "Statistical description of original dataset\n",
            "\n",
            "            Category  ModeScore  MeanScore  StdDev\n",
            "0  Rater 1 - Valence          9      7.064   2.104\n",
            "1  Rater 1 - Arousal          7      6.085   2.155\n",
            "2  Rater 2 - Valence          8      6.870   2.099\n",
            "3  Rater 2 - Arousal          7      6.193   2.129\n",
            "4  Average - Valence          8      6.905   1.986\n",
            "5  Average - Arousal          8      6.136   2.061\n",
            "******************************************************************************************\n",
            "@@@ Start bagging process...\n",
            "... Bagging completed in 25.8852 seconds @@@\n",
            "@@@ Start encoding process...\n",
            "... Encoding completed in 0.9934 seconds @@@\n",
            "Rules-based mining for X_Rater 1 - Valence\n",
            "\n",
            "******************************************************************************************\n",
            "Modeling with Rule-based ...\n",
            "                                            Antecedent Consequent  Accuracy  Coverage\n",
            "0                                                   []   negative     0.650     0.440\n",
            "1                                       [(good > 0.5)]   negative     0.600     0.230\n",
            "2                       [(good > 0.5), (pretty > 0.5)]    neutral     0.470     0.050\n",
            "3                         [(star > 0.5), (food > 0.5)]    neutral     0.660     0.040\n",
            "4                                       [(star > 0.5)]    neutral     0.450     0.020\n",
            "..                                                 ...        ...       ...       ...\n",
            "99   [(good > 0.5), (wasnt > 0.5), (meat > 0.5), (o...   positive     1.000     0.000\n",
            "100  [(rude > 0.5), (great > 0.5), (incredible > 0.5)]   negative     1.000     0.000\n",
            "101  [(rude > 0.5), (great > 0.5), (unbearable > 0.5)]   positive     1.000     0.000\n",
            "102                      [(rude > 0.5), (great > 0.5)]    neutral     1.000     0.000\n",
            "103         [(star > 0.5), (list > 0.5), (idea > 0.5)]    neutral     1.000     0.000\n",
            "\n",
            "[104 rows x 4 columns]\n",
            "file X_Rater 1 - Valence.csv save complete\n",
            "... Rule-based took 1.8854 seconds to complete\n",
            "******************************************************************************************\n",
            "\n",
            "Rules-based mining for X_Rater 1 - Arousal\n",
            "\n",
            "******************************************************************************************\n",
            "Modeling with Rule-based ...\n",
            "                                           Antecedent         Consequent  Accuracy  Coverage\n",
            "0                                                  []  somewhat positive     0.360     0.490\n",
            "1                                    [(really > 0.5)]  somewhat positive     0.550     0.100\n",
            "2                                      [(dont > 0.5)]  somewhat negative     0.320     0.090\n",
            "3                                      [(love > 0.5)]  somewhat negative     0.400     0.090\n",
            "4                                   [(amazing > 0.5)]  somewhat negative     0.450     0.070\n",
            "..                                                ...                ...       ...       ...\n",
            "73  [(amazing > 0.5), (ill > 0.5), (stick > 0.5), ...  somewhat positive     1.000     0.000\n",
            "74     [(love > 0.5), (wine > 0.5), (innocent > 0.5)]  somewhat positive     1.000     0.000\n",
            "75      [(amazing > 0.5), (ill > 0.5), (stick > 0.5)]  somewhat positive     1.000     0.000\n",
            "76         [(love > 0.5), (free > 0.5), (cash > 0.5)]  somewhat positive     1.000     0.000\n",
            "77  [(god > 0.5), (im > 0.5), (favorite > 0.5), (l...  somewhat positive     1.000     0.000\n",
            "\n",
            "[78 rows x 4 columns]\n",
            "file X_Rater 1 - Arousal.csv save complete\n",
            "... Rule-based took 0.9410 seconds to complete\n",
            "******************************************************************************************\n",
            "\n",
            "Rules-based mining for X_Rater 2 - Valence\n",
            "\n",
            "******************************************************************************************\n",
            "Modeling with Rule-based ...\n",
            "                                           Antecedent         Consequent  Accuracy  Coverage\n",
            "0                                                  []           negative     0.610     0.580\n",
            "1                                    [(little > 0.5)]           negative     0.490     0.080\n",
            "2                                     [(worth > 0.5)]           negative     0.470     0.060\n",
            "3                                     [(think > 0.5)]  somewhat negative     0.380     0.060\n",
            "4                                     [(didnt > 0.5)]           negative     0.440     0.030\n",
            "..                                                ...                ...       ...       ...\n",
            "86           [(overpriced > 0.5), (phenomenal > 0.5)]           negative     1.000     0.000\n",
            "87              [(overpriced > 0.5), (spanish > 0.5)]           positive     1.000     0.000\n",
            "88  [(think > 0.5), (away > 0.5), (use > 0.5), (am...  somewhat positive     1.000     0.000\n",
            "89  [(overpriced > 0.5), (cheese > 0.5), (shut > 0...           positive     1.000     0.000\n",
            "90  [(ok > 0.5), (waiter > 0.5), (thought > 0.5), ...           positive     1.000     0.000\n",
            "\n",
            "[91 rows x 4 columns]\n",
            "file X_Rater 2 - Valence.csv save complete\n",
            "... Rule-based took 0.9370 seconds to complete\n",
            "******************************************************************************************\n",
            "\n",
            "Rules-based mining for X_Rater 2 - Arousal\n",
            "\n",
            "******************************************************************************************\n",
            "Modeling with Rule-based ...\n",
            "                                         Antecedent         Consequent  Accuracy  Coverage\n",
            "0                                                []  somewhat positive     0.360     0.570\n",
            "1                                    [(love > 0.5)]            neutral     0.450     0.100\n",
            "2                                 [(amazing > 0.5)]            neutral     0.430     0.080\n",
            "3                                     [(bit > 0.5)]           positive     0.250     0.060\n",
            "4                                [(probably > 0.5)]  somewhat positive     0.600     0.040\n",
            "..                                              ...                ...       ...       ...\n",
            "56      [(love > 0.5), (flavor > 0.5), (jam > 0.5)]            neutral     1.000     0.000\n",
            "57  [(love > 0.5), (overall > 0.5), (ginger > 0.5)]  somewhat positive     1.000     0.000\n",
            "58      [(wish > 0.5), (far > 0.5), (people > 0.5)]            neutral     1.000     0.000\n",
            "59     [(love > 0.5), (flavor > 0.5), (wrap > 0.5)]            neutral     1.000     0.000\n",
            "60     [(wish > 0.5), (star > 0.5), (agreed > 0.5)]            neutral     1.000     0.000\n",
            "\n",
            "[61 rows x 4 columns]\n",
            "file X_Rater 2 - Arousal.csv save complete\n",
            "... Rule-based took 0.9175 seconds to complete\n",
            "******************************************************************************************\n",
            "\n",
            "Rules-based mining for X_Average - Valence\n",
            "\n",
            "******************************************************************************************\n",
            "Modeling with Rule-based ...\n",
            "                                            Antecedent         Consequent  Accuracy  Coverage\n",
            "0                                                   []           negative     0.730     0.520\n",
            "1                                       [(like > 0.5)]           negative     0.500     0.110\n",
            "2                                      [(think > 0.5)]  somewhat negative     0.410     0.040\n",
            "3                                       [(star > 0.5)]           negative     0.570     0.030\n",
            "4                         [(like > 0.5), (menu > 0.5)]           negative     0.850     0.030\n",
            "..                                                 ...                ...       ...       ...\n",
            "111  [(like > 0.5), (turned > 0.5), (best > 0.5), (...           negative     1.000     0.000\n",
            "112  [(like > 0.5), (turned > 0.5), (best > 0.5), (...  somewhat negative     1.000     0.000\n",
            "113         [(like > 0.5), (turned > 0.5), (mu > 0.5)]           negative     1.000     0.000\n",
            "114  [(think > 0.5), (star > 0.5), (going > 0.5), (...           negative     1.000     0.000\n",
            "115      [(bad > 0.5), (favorite > 0.5), (wong > 0.5)]           positive     1.000     0.000\n",
            "\n",
            "[116 rows x 4 columns]\n",
            "file X_Average - Valence.csv save complete\n",
            "... Rule-based took 0.8836 seconds to complete\n",
            "******************************************************************************************\n",
            "\n",
            "Rules-based mining for X_Average - Arousal\n",
            "\n",
            "******************************************************************************************\n",
            "Modeling with Rule-based ...\n",
            "                                           Antecedent         Consequent  Accuracy  Coverage\n",
            "0                                                  []  somewhat positive     0.380     0.560\n",
            "1                                      [(love > 0.5)]  somewhat negative     0.510     0.090\n",
            "2                                   [(amazing > 0.5)]  somewhat negative     0.590     0.070\n",
            "3                                      [(dont > 0.5)]  somewhat negative     0.310     0.070\n",
            "4                                      [(wish > 0.5)]  somewhat negative     0.920     0.020\n",
            "..                                                ...                ...       ...       ...\n",
            "86  [(amazing > 0.5), (cheese > 0.5), (ethereal > ...           positive     1.000     0.000\n",
            "87  [(amazing > 0.5), (hard > 0.5), (outdoors > 0.5)]  somewhat positive     1.000     0.000\n",
            "88       [(dont > 0.5), (bean > 0.5), (crispy > 0.5)]  somewhat negative     1.000     0.000\n",
            "89       [(love > 0.5), (staple > 0.5), (york > 0.5)]           positive     1.000     0.000\n",
            "90                       [(wow > 0.5), (brown > 0.5)]           positive     1.000     0.000\n",
            "\n",
            "[91 rows x 4 columns]\n",
            "file X_Average - Arousal.csv save complete\n",
            "... Rule-based took 0.8758 seconds to complete\n",
            "******************************************************************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}